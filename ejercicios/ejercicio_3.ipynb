{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab20507",
   "metadata": {},
   "source": [
    "#aqui va el script del problema 3\n",
    "#AQUI VA EL SCRIPT DEL EJERCICIO 3\n",
    "#AQUI\n",
    "# Script para el Ejercicio 3: Comparación Pandas vs PySpark con el dataset AirQualityUCI\n",
    "# 1 Importación de Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#  2Ruta del Archivo\n",
    "#la 'r' al inicio es importante en Windows/SEGUN el video, se recomienda eso, igual puedo poner que recise la existencia para luego descargar \n",
    "CSV_FILE = r'C:\\Users\\diego\\Desktop\\PROYECTO_\\datos\\ejer_3\\AirQualityUCI.csv'\n",
    "# 3 Funciones de Procesamiento\n",
    "def limpiar_data(df):\n",
    "    \"\"\"\n",
    "    Realiza una limpieza exhaustiva del DataFrame de Calidad del Aire.\n",
    "    - Elimina columnas y filas vacías.\n",
    "    - Reemplaza el marcador de nulos (-200) por NaN.\n",
    "    - Convierte las columnas de fecha y hora a un índice de tipo datetime.\n",
    "    \"\"\"\n",
    "    print(\"[Limpieza] Inciando limpieza de datos...\")\n",
    "    #Eliminar las dos columnas(creo que estan vacias)\n",
    "    df = df.iloc[:, :-2]\n",
    "    #Eliminar filas donde todos los valores son nulo\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    # Reemplazar el valor -200 (marcador de nulos específico de este dataset) con NaN de numpy\n",
    "    df.replace(to_replace=-200, value=np.nan, inplace=True)\n",
    "    # Combinar Date y Time en una sola columna de tipo datetime para análisis de series de tiempo\n",
    "    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H.%M.%S')\n",
    "    df.set_index('DateTime', inplace=True)\n",
    "    df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "    print(\"[Limpieza] Limpieza completada.\")\n",
    "    return df\n",
    "def _pandas(df):\n",
    "    \"\"\"\n",
    "    Realiza las operaciones de filtrado, agrupamiento e imputación con Pandas\n",
    "    y muestra los resultados en la consola.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ANALISIS CON PANDAS\")\n",
    "    print(\"=\"*50)\n",
    "    # 1 filtro que puede servir: dias con temperatura mayor a 25C\n",
    "    print(\"\\n[PANDAS] 1. Filtrando registros con Temperatura > 25C...\")\n",
    "    dias_calurosos = df[df['T'] > 25]\n",
    "    print(f\"Se encontraron {len(dias_calurosos)} registros/horas con T > 25°C.\")\n",
    "    print(\"Mostrando los 5 primeros registros de días calurosos:\")\n",
    "    # .to_string() asegura que se vea bien en la terminal o que se vea, n0 logro que se vea bien \n",
    "    print(dias_calurosos[['T', 'RH', 'AH']].head().to_string())\n",
    "    print(\"-\" * 50)\n",
    "    # 2 calcular y mostrar la media de tem  diaria? o de algun lugar especifico (benceno (C6H6)(porque este???))\n",
    "    print(\"\\n[PANDAS] 2. Calculando la media diaria de Benceno (C6H6(GT))...\")\n",
    "    # .resample('D') es una poderosa función para agrupar por día\n",
    "    media_diaria_benceno = df['C6H6(GT)'].resample('D').mean()\n",
    "    print(\"Mostrando la media de los últimos 5 días con registros:\")\n",
    "    print(media_diaria_benceno.dropna().tail().to_string())\n",
    "    print(\"-\" * 50)\n",
    "    # 3 Benceno(no encerio porque este?)mostramos la media, mediana y el metodo ffill para hacer algo con los nulos, deja buscar que es ffill\n",
    "    # ffill es fill forward, osea que llena con el ultimo valor conocido, osea que si hay nulos seguidos, los llena con el ultimo valor que no es nulo\n",
    "    #aver que resulta(no le tengo mucha fe(lol))\n",
    "    print(\"\\n[PANDAS] 3 realizando imputación en la columna 'C6H6(GT)'...\")\n",
    "    columna_benceno = df[['C6H6(GT)']].copy()\n",
    "    columna_benceno['C6H6_con_media'] = columna_benceno['C6H6(GT)'].fillna(columna_benceno['C6H6(GT)'].mean())\n",
    "    columna_benceno['C6H6_con_mediana'] = columna_benceno['C6H6(GT)'].fillna(columna_benceno['C6H6(GT)'].median())\n",
    "    columna_benceno['C6H6_con_ffill'] = columna_benceno['C6H6(GT)'].fillna(method='ffill')\n",
    "    print(\"\\nVerificación de imputación (mostrando 5 filas donde el valor original era nulo):\")\n",
    "    print(columna_benceno[columna_benceno['C6H6(GT)'].isnull()].head().to_string())\n",
    "#dejo esto o lo paso al java?/igual lo dejo expresado en el java(tengo muchas dudas si se puede java y python en el mismo proyecto)\n",
    "def _pyspark():\n",
    "    \"\"\"\n",
    "    como seria, muestra de lo que seria el codigo en pyspark\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EJEMPLO DE CÓDIGO(compraracion)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    codigo_pyspark = \"\"\"\n",
    "# Para ejecutar esto, se necesita una instal de Java y Spark.(por ahora eso es lo necesario)\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, avg, to_date\n",
    "# spark = SparkSession.builder.appName(\"AirQualitySpark\").getOrCreate()\n",
    "\n",
    "# # lectura del csv para el spark.manejo de decimales con ','\n",
    "# # puede requerir filtrar data.(segun la guia(video))\n",
    "# df_spark = spark.read.csv(\n",
    "#     r'C:\\\\Users\\\\diego\\\\Desktop\\\\PROYECTO_\\\\datos\\\\ejer_3\\\\AirQualityUCI.csv',\n",
    "#     header=True,\n",
    "#     sep=';',\n",
    "#     inferSchema=True\n",
    "# ).replace(-200, None) # Reemplazar -200 por nulos\n",
    "\n",
    "# # convertir columna de fecha y agrupar /utilizar la misma locacion de benceno \n",
    "# df_spark = df_spark.withColumn('Date', to_date(col('Date'), 'dd/MM/yyyy'))\n",
    "# media_diaria_benceno_spark = df_spark.groupBy('Date').agg(avg('C6H6(GT)').alias('media_benceno'))\n",
    "\n",
    "# print(\"Resultado de PySpark (media diaria de Benceno):\")\n",
    "# media_diaria_benceno_spark.orderBy('Date', ascending=False).show(5)\n",
    "# spark.stop()\n",
    "    \"\"\"\n",
    "    print(codigo_pyspark)\n",
    "#4 Ejecución!(esta bien escrito/creo)\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Funcin principal que orquesta la ejecución del script.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Carga de datos especificos \n",
    "        print(f\"Cargando dataset desde: {CSV_FILE}...\")\n",
    "        air_df = pd.read_csv(CSV_FILE, sep=';', decimal=',')\n",
    "        # Limpieza de basura\n",
    "        air_df_limpio = limpiar_data(air_df)\n",
    "        print(f\"Dimensiones del dataset limpio: {air_df_limpio.shape}\")\n",
    "        # se hace analisis\n",
    "        _pandas(air_df_limpio)\n",
    "        # Mostrar el código de ejemplo de PySpark\n",
    "        _pyspark()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"error: No se encontro el archivo.\")\n",
    "        print(f\"Ruta: '{CSV_FILE}'\")\n",
    "        print(\"Por favor, verifica que la ruta sea correcta y que el archivo exista.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado: {e}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"\\n--- Script Finalizado ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f541a818",
   "metadata": {},
   "source": [
    "# Ejercicio 3: Comparación Pandas vs PySpark\n",
    "carga, limpia y analiza el dataset `AirQualityUCI` utilizando Pandas. Al final, muestra un ejemplo de cómo se realizarían operaciones similares en PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Archivo encontrado en:\n",
      "C:\\Users\\diego\\Desktop\\PROYECTO_\\datos\\ejer_3\\AirQualityUCI.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuración de la ruta del archivo ---\n",
    "# ¡IMPORTANTE! Asegúrate de que esta ruta sea correcta en tu sistema.\n",
    "URL=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip\"\n",
    "\n",
    "CSV_FILE = r'C:\\Users\\diego\\Desktop\\PROYECTO_\\datos\\ejer_3\\AirQualityUCI.csv'\n",
    "# Verificamos si el archivo existe para evitar errores\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    print(f\" ERROR: No se pudo encontrar el archivo en la ruta:\\n{CSV_FILE}\")\n",
    "else:\n",
    "    print(f\" Archivo encontrado en:\\n{CSV_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e5cb8",
   "metadata": {},
   "source": [
    "# definimos las fuciones de procesamiento y/o filtracion\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71228c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_data(df):\n",
    "    \"\"\"\n",
    "    Realiza una limpieza exhaustiva del DataFrame de Calidad del Aire.\n",
    "    - Elimina columnas y filas vacías.\n",
    "    - Reemplaza el marcador de nulos (-200) por NaN.\n",
    "    - Convierte las columnas de fecha y hora a un índice de tipo datetime.\n",
    "    \"\"\"\n",
    "    print(\"[Limpieza] Iniciando limpieza de datos...\")\n",
    "    \n",
    "    # Eliminar las dos últimas columnas que suelen estar vacías\n",
    "    df_cleaned = df.iloc[:, :-2].copy()\n",
    "    \n",
    "    # Eliminar filas donde todos los valores son nulos\n",
    "    df_cleaned.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # Reemplazar el valor -200 con NaN de numpy\n",
    "    df_cleaned.replace(to_replace=-200, value=np.nan, inplace=True)\n",
    "    \n",
    "    # Combinar Date y Time en una sola columna de tipo datetime\n",
    "    df_cleaned['DateTime'] = pd.to_datetime(df_cleaned['Date'] + ' ' + df_cleaned['Time'], format='%d/%m/%Y %H.%M.%S', errors='coerce')\n",
    "    df_cleaned.set_index('DateTime', inplace=True)\n",
    "    df_cleaned.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "    \n",
    "    print(\"[Limpieza] Limpieza completada.\")\n",
    "    return df_cleaned\n",
    "\n",
    "def analisis_pandas(df):\n",
    "    \"\"\"\n",
    "    Realiza las operaciones de filtrado, agrupamiento e imputación con Pandas.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ANÁLISIS CON PANDAS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 1. Filtrar registros con Temperatura > 25°C\n",
    "    print(\"\\n[PANDAS] 1. Filtrando registros con Temperatura > 25°C...\")\n",
    "    dias_calurosos = df[df['T'] > 25]\n",
    "    print(f\"Se encontraron {len(dias_calurosos)} registros/horas con T > 25°C.\")\n",
    "    print(\"Mostrando los 5 primeros registros de días calurosos:\")\n",
    "    display(dias_calurosos[['T', 'RH', 'AH']].head())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Calcular la media diaria de Benceno\n",
    "    print(\"\\n[PANDAS] 2. Calculando la media diaria de Benceno (C6H6(GT))...\")\n",
    "    media_diaria_benceno = df['C6H6(GT)'].resample('D').mean()\n",
    "    print(\"Mostrando la media de los últimos 5 días con registros:\")\n",
    "    display(media_diaria_benceno.dropna().tail())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 3. Realizar imputación en la columna 'C6H6(GT)'\n",
    "    print(\"\\n[PANDAS] 3. Realizando imputación en la columna 'C6H6(GT)'...\")\n",
    "    columna_benceno = df[['C6H6(GT)']].copy()\n",
    "    columna_benceno['C6H6_con_media'] = columna_benceno['C6H6(GT)'].fillna(columna_benceno['C6H6(GT)'].mean())\n",
    "    columna_benceno['C6H6_con_mediana'] = columna_benceno['C6H6(GT)'].fillna(columna_benceno['C6H6(GT)'].median())\n",
    "    columna_benceno['C6H6_con_ffill'] = columna_benceno['C6H6(GT)'].fillna(method='ffill')\n",
    "    print(\"\\nVerificación de imputación (mostrando 5 filas donde el valor original era nulo):\")\n",
    "    display(columna_benceno[columna_benceno['C6H6(GT)'].isnull()].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9d63f",
   "metadata": {},
   "source": [
    "# Cargamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949bc38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset desde: C:\\Users\\diego\\Desktop\\PROYECTO_\\datos\\ejer_3\\AirQualityUCI.csv...\n",
      "[Limpieza] Iniciando limpieza de datos...\n",
      "[Limpieza] Limpieza completada.\n",
      "\n",
      "Dimensiones del dataset limpio: (9357, 13)\n",
      "Primeras 5 filas del dataset limpio:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-10 18:00:00</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 19:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 20:00:00</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 21:00:00</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 22:00:00</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "DateTime                                                                      \n",
       "2004-03-10 18:00:00     2.6       1360.0     150.0      11.9         1046.0   \n",
       "2004-03-10 19:00:00     2.0       1292.0     112.0       9.4          955.0   \n",
       "2004-03-10 20:00:00     2.2       1402.0      88.0       9.0          939.0   \n",
       "2004-03-10 21:00:00     2.2       1376.0      80.0       9.2          948.0   \n",
       "2004-03-10 22:00:00     1.6       1272.0      51.0       6.5          836.0   \n",
       "\n",
       "                     NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
       "DateTime                                                            \n",
       "2004-03-10 18:00:00    166.0        1056.0    113.0        1692.0   \n",
       "2004-03-10 19:00:00    103.0        1174.0     92.0        1559.0   \n",
       "2004-03-10 20:00:00    131.0        1140.0    114.0        1555.0   \n",
       "2004-03-10 21:00:00    172.0        1092.0    122.0        1584.0   \n",
       "2004-03-10 22:00:00    131.0        1205.0    116.0        1490.0   \n",
       "\n",
       "                     PT08.S5(O3)     T    RH      AH  \n",
       "DateTime                                              \n",
       "2004-03-10 18:00:00       1268.0  13.6  48.9  0.7578  \n",
       "2004-03-10 19:00:00        972.0  13.3  47.7  0.7255  \n",
       "2004-03-10 20:00:00       1074.0  11.9  54.0  0.7502  \n",
       "2004-03-10 21:00:00       1203.0  11.0  60.0  0.7867  \n",
       "2004-03-10 22:00:00       1110.0  11.2  59.6  0.7888  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"Cargando dataset desde: {CSV_FILE}...\")\n",
    "    air_df = pd.read_csv(CSV_FILE, sep=';', decimal=',')\n",
    "    \n",
    "    # Limpieza de datos\n",
    "    air_df_limpio = limpiar_data(air_df)\n",
    "    \n",
    "    print(f\"\\nDimensiones del dataset limpio: {air_df_limpio.shape}\")\n",
    "    print(\"Primeras 5 filas del dataset limpio:\")\n",
    "    display(air_df_limpio.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\" ERROR: No se encontró el archivo en la ruta '{CSV_FILE}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935374a",
   "metadata": {},
   "source": [
    "# con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba1065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ANÁLISIS CON PANDAS\n",
      "==================================================\n",
      "\n",
      "[PANDAS] 1. Filtrando registros con Temperatura > 25°C...\n",
      "Se encontraron 2059 registros/horas con T > 25°C.\n",
      "Mostrando los 5 primeros registros de días calurosos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-16 13:00:00</th>\n",
       "      <td>25.3</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.8264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-16 14:00:00</th>\n",
       "      <td>25.8</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.7589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-16 15:00:00</th>\n",
       "      <td>27.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.7094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-16 16:00:00</th>\n",
       "      <td>28.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.7014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-16 17:00:00</th>\n",
       "      <td>28.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.7098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        T    RH      AH\n",
       "DateTime                               \n",
       "2004-03-16 13:00:00  25.3  26.1  0.8264\n",
       "2004-03-16 14:00:00  25.8  23.2  0.7589\n",
       "2004-03-16 15:00:00  27.0  20.2  0.7094\n",
       "2004-03-16 16:00:00  28.2  18.6  0.7014\n",
       "2004-03-16 17:00:00  28.0  19.1  0.7098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "[PANDAS] 2. Calculando la media diaria de Benceno (C6H6(GT))...\n",
      "Mostrando la media de los últimos 5 días con registros:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2005-03-31    5.220833\n",
       "2005-04-01    3.412500\n",
       "2005-04-02    2.529167\n",
       "2005-04-03    4.316667\n",
       "2005-04-04    8.440000\n",
       "Name: C6H6(GT), dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "[PANDAS] 3. Realizando imputación en la columna 'C6H6(GT)'...\n",
      "\n",
      "Verificación de imputación (mostrando 5 filas donde el valor original era nulo):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_14724\\3703551525.py:55: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  columna_benceno['C6H6_con_ffill'] = columna_benceno['C6H6(GT)'].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>C6H6_con_media</th>\n",
       "      <th>C6H6_con_mediana</th>\n",
       "      <th>C6H6_con_ffill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-04-01 14:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.083105</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01 15:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.083105</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01 16:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.083105</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-08 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.083105</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-09 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.083105</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     C6H6(GT)  C6H6_con_media  C6H6_con_mediana  \\\n",
       "DateTime                                                          \n",
       "2004-04-01 14:00:00       NaN       10.083105               8.2   \n",
       "2004-04-01 15:00:00       NaN       10.083105               8.2   \n",
       "2004-04-01 16:00:00       NaN       10.083105               8.2   \n",
       "2004-04-08 23:00:00       NaN       10.083105               8.2   \n",
       "2004-04-09 00:00:00       NaN       10.083105               8.2   \n",
       "\n",
       "                     C6H6_con_ffill  \n",
       "DateTime                             \n",
       "2004-04-01 14:00:00             8.6  \n",
       "2004-04-01 15:00:00             8.6  \n",
       "2004-04-01 16:00:00             8.6  \n",
       "2004-04-08 23:00:00             6.3  \n",
       "2004-04-09 00:00:00             6.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se ejecuta el análisis solo si el DataFrame 'air_df_limpio' se creó correctamente\n",
    "if 'air_df_limpio' in locals():\n",
    "    analisis_pandas(air_df_limpio)\n",
    "else:\n",
    "    print(\"El DataFrame 'air_df_limpio' no fue creado. Por favor, revisa la celda anterior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec2e46",
   "metadata": {},
   "source": [
    "# pyspark\n",
    " por problemas con java y no saber configurarlo bien no lo tengo ejecutable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
